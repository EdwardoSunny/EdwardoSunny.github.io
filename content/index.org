#+OPTIONS: toc:nil title:nil
#+TITLE: Edward Sun

#+BEGIN_EXPORT html
<header class="site-header">
  <div class="site-title">Edward Sun</div>
  <nav class="site-nav">
    <a href="./writings.html">Writings</a>
    <a href="./papers.html">Papers</a>
    <a href="./contact.html">Contact</a>
  </nav>
</header>
#+END_EXPORT

#+BEGIN_EXPORT html
<section class="hero">
  <img src="./assets/me.jpeg" alt="Portrait" />
  <div>
    <p class="intro">I am a third-year computer science student at UCLA. I work closely with <a href="https://yijia-xiao.com/">Yijia Xiao</a> and I am advised by <a href="https://web.cs.ucla.edu/~weiwang/">Wei Wang</a> and <a href="https://yuchencui.cc/">Professor Yuchen Cui</a>. I also actively collaborate with <a href="https://yuchenlwu.github.io/">Yuchen Wu</a> from the University of Washington, and work jointly with <a href="https://jd92.wang/">Professor Jindong Wang</a> at William &amp; Mary.

    </br></br>

    I have worked on <b>multimodal large language models, reasoning, and agentic systems</b>, with applications in biology, finance, and robotics. During my time working on agents and reasoning for finance applications, I co-founded the opensource research community <a href="https://github.com/TauricResearch">Tauric Research</a> with my amazing mentor <a href="https://yijia-xiao.com/">Yijia Xiao</a>. I am currently interested in questions of <b>safety, robustness, and interpretability</b> in foundational models and their applications.

    </br></br>

    I was named a <a href="https://www.cs.ucla.edu/sophomore-cs-student-earns-2025-goldwater-scholarship/">Goldwater Scholar</a> in 2025. </p> 


    <p class="subtle">This site hosts my writings, research, and ways to get in touch.</p>
  </div>
</section>
#+END_EXPORT


* Highlights
#+BEGIN_EXPORT html
<div class="paper-list">
  <article class="paper-item">
    <div>
      <h3 class="paper-title"><a href="https://arxiv.org/abs/2505.18882">Personalized Safety in LLMs: A Benchmark and A Planning-Based Agent Approach</a></h3>
      <p class="paper-authors">Yuchen Wu, <strong>Edward Sun</strong>, Kaijie Zhu, Jianxun Lian, Jose Hernandez-Orallo, Aylin Caliskan, Jindong Wang</p>
      <p class="paper-meta">NeurIPS 2025</p>
      <p class="paper-blurb">Introduced the need to study personalized safety in LLMs. Argued that alignment should not be purely global, but tailored to a user's background since risk profiles vary across users. Showed where current models fall short, and introduced an inference-time mitigation approach using LLM-guided Monte Carlo Tree Search.</p>
    </div>
  </article>

  <article class="paper-item">
    <div>
      <h3 class="paper-title"><a href="https://arxiv.org/abs/2509.11420">Trading-R1: Financial trading with llm reasoning via reinforcement learning</a></h3>
      <p class="paper-authors">Y Xiao, <strong>Edward Sun</strong>, T Chen, F Wu, D Luo, W Wang</p>
      <p class="paper-meta">arXiv preprint arXiv:2509.11420</p>
      <p class="paper-blurb">Trading-R1 is an RL-trained reasoning LLM that transforms heterogeneous financial signals into structured, auditable investment theses and volatility-aware trade ratings by learning multi-perspective financial reasoning through reverse chain-of-thought distillation and an easy-to-hard RL curriculum, achieving superior risk-adjusted backtest performance over generic instruction-following and reasoning models.</p>
    </div>
  </article>

  <article class="paper-item">
    <div>
      <h3 class="paper-title"><a href="https://arxiv.org/abs/2412.20138">TradingAgents: Multi-Agents LLM Financial Trading Framework</a></h3>
      <p class="paper-authors">Yijia Xiao, <strong>Edward Sun</strong>, Di Luo, Wei Wang</p>
      <p class="paper-meta">MARW@AAAI 2025 <span class="badge">Oral</span></p>
      <p class="paper-blurb">A multi-agent LLM framework for financial trading, with agents crawling technical, news, sentiment, and more to make a trading decision. <a href="https://github.com/TauricResearch/TradingAgents">GitHub (27k stars)</a></p>
    </div>
  </article>

  <article class="paper-item">
    <div>
      <h3 class="paper-title"><a href="https://arxiv.org/abs/2408.11363">ProteinGPT: Multimodal LLM for protein property prediction and structure understanding</a></h3>
      <p class="paper-authors">Y Xiao, <strong>Edward Sun</strong>, Y Jin, Q Wang, W Wang</p>
      <p class="paper-meta">ICLR 2025 MLGenX <span class="badge">Spotlight</span></p>
      <p class="paper-blurb">ProteinGPT is a multimodal LLM that accelerates protein research by enabling natural language interaction with protein sequences and structures. Trained on over 130,000 proteins, it integrates evolutionary-scale protein folding and inverse folding models (esm2) to encode sequence and structural information, aligns these modalities with language, and is instruction-tuned to deliver an interactive, high-performance protein-focused chat experience.</p>
    </div>
  </article>

</div>
#+END_EXPORT
